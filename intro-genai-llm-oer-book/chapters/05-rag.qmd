---
title: "Chapter 5: Retrieval-Augmented Generation"
---

Chapter 5: Retrieval-Augmented Generation (RAG)

Introduction to the Chapter

While Large Language Models possess impressive knowledge from their training data, they face fundamental limitations: knowledge cutoffs, inability to access private or recent information, and potential hallucinations about facts. Retrieval-Augmented Generation (RAG) solves these challenges by combining the reasoning capabilities of LLMs with the precision and currency of external knowledge sources.

RAG represents a paradigm shift from static, closed-book AI systems to dynamic, open-book systems that can access, evaluate, and synthesize information from vast external sources in real-time. This approach is essential for building AI systems that can work with proprietary documents, stay current with rapidly changing information, and provide verifiable, source-backed responses.

In this chapter, you'll transform your research assistant into a knowledge-powered system capable of ingesting documents, building searchable knowledge bases, and providing responses grounded in specific, retrievable sources. You'll learn to build the semantic search infrastructure that powers modern AI applications, from customer support systems to research platforms.

Introductory Video

[Video: "Beyond Training Data - Building Knowledge-Powered AI Systems" - 16 minutes]

- Limitations of pre-trained knowledge and the need for external sources
- RAG architecture overview and real-world applications
- Comparison of different retrieval approaches and their trade-offs
- Success stories: customer support, research, and enterprise knowledge systems

Learning Outcomes

By the end of this chapter, you will be able to:

- Understand the fundamental principles and architecture of Retrieval-Augmented Generation
- Design and implement document ingestion pipelines for various content types
- Build vector databases and semantic search systems for knowledge retrieval
- Create effective embedding strategies for different types of content
- Optimize retrieval performance through chunking, indexing, and query strategies
- Implement hybrid search combining semantic and keyword-based approaches
- Develop context-aware response generation using retrieved information
- Build source attribution and citation systems for transparency
- Design knowledge base management and updating workflows
- Evaluate RAG system performance using both technical and user-centric metrics

Key Terminologies and Concepts

Main Book Sections

5.1 Understanding Retrieval-Augmented Generation

The Knowledge Problem in LLMs

Large Language Models face several fundamental limitations that RAG addresses:

Knowledge Cutoff: Models are trained on data up to a specific date and cannot access information beyond that point. A model trained in 2023 won't know about events in 2024.

Private Information: Models cannot access proprietary documents, internal company knowledge, or user-specific information that wasn't in their training data.

Factual Accuracy: Models can generate plausible-sounding but incorrect information (hallucinations), especially about specific facts, dates, or statistics.

Dynamic Information: Information that changes frequently (stock prices, news, weather) requires real-time access rather than static training data.

RAG Architecture Overview

RAG systems typically follow a two-stage process:

Stage 1: Retrieval

- Convert user query into a search-optimized format
- Search knowledge base for relevant information
- Rank and select the most relevant chunks
- Prepare context for the generation stage
Stage 2: Generation

- Combine retrieved information with user query
- Generate response using LLM with augmented context
- Ensure response is grounded in retrieved information
- Provide source attribution and citations
Benefits of RAG Approach

- Accuracy: Responses grounded in specific, verifiable sources
- Currency: Access to up-to-date information
- Transparency: Clear source attribution for fact-checking
- Customization: Easy addition of domain-specific knowledge
- Cost-Effectiveness: No need to retrain models for new information
5.2 Vector Databases and Semantic Search

Understanding Embeddings

Embeddings transform text into high-dimensional vectors that capture semantic meaning. Similar concepts have similar vector representations, enabling mathematical operations on meaning.

Key Properties of Good Embeddings:

- Semantic Similarity: Related concepts cluster together in vector space
- Dimensionality: Typically 384, 768, or 1536 dimensions
- Consistency: Same text always produces the same embedding
- Language Awareness: Understanding of grammar, context, and meaning
Popular Embedding Models:

OpenAI text-embedding-ada-002

1. dimensions, excellent general performance
- Strong multilingual capabilities
- Optimized for retrieval tasks
Sentence-BERT Models

- Various sizes and specializations available
- Can be fine-tuned for specific domains
- Good balance of performance and computational efficiency
Domain-Specific Models

- Scientific papers: SciBERT, BioBERT
- Legal documents: LegalBERT
- Code: CodeBERT, GraphCodeBERT
Vector Database Technologies

Cloud-Native Solutions:

- Pinecone: Managed vector database with excellent performance
- Weaviate: Open-source with rich feature set
- Qdrant: High-performance with flexible filtering
Self-Hosted Options:

- FAISS: Facebook's library for efficient similarity search
- Chroma: Simple, developer-friendly vector database
- Milvus: Production-scale vector database
Database Selection Criteria:

- Scale: Document volume and query throughput requirements
- Performance: Latency and accuracy requirements
- Features: Metadata filtering, hybrid search, real-time updates
- Cost: Pricing model and operational overhead
- Integration: Compatibility with existing tech stack
5.3 Document Processing and Ingestion

Document Processing Pipeline

Step 1: Content Extraction Different document types require specialized extraction:

- PDF: Text extraction, OCR for scanned documents, table/image handling
- Web Pages: HTML parsing, content extraction, link following
- Office Documents: Word, PowerPoint, Excel processing
- Code Repositories: Syntax-aware chunking, documentation extraction
- Structured Data: JSON, CSV, database exports
Step 2: Text Preprocessing

- Cleaning: Remove formatting artifacts, normalize whitespace
- Language Detection: Identify document language for appropriate processing
- Quality Filtering: Remove low-quality or duplicate content
- Structure Preservation: Maintain headings, sections, and context
Step 3: Chunking Strategy Breaking documents into optimal pieces for retrieval:

Fixed-Size Chunking

- Simple approach: split every N characters or tokens
- Pros: Predictable chunk sizes, simple implementation
- Cons: May break semantic units, lose context
Semantic Chunking

- Split on natural boundaries (sentences, paragraphs, sections)
- Preserve meaning and context within chunks
- More complex but better for retrieval quality
Overlapping Chunks

- Include overlap between adjacent chunks to preserve context
- Typical overlap: 10-20% of chunk size
- Helps ensure important information isn't lost at boundaries
Hierarchical Chunking

- Multiple levels: document → section → paragraph → sentence
- Enables retrieval at different granularities
- More complex but provides richer context options
5.4 Advanced Retrieval Techniques

Hybrid Search Strategies

Combining multiple search approaches for better results:

Semantic + Keyword Search

- Vector similarity for semantic matching
- BM25/TF-IDF for exact term matching
- Weighted combination of scores
Multi-Vector Approaches

- Different embeddings for different content types
- Query expansion using multiple related queries
- Cross-encoder reranking for final results
Query Enhancement Techniques

Query Expansion

- Add related terms and synonyms to original query
- Use LLM to generate alternative phrasings
- Include domain-specific terminology
Query Decomposition

- Break complex queries into simpler sub-queries
- Process each sub-query independently
- Combine results intelligently
Contextual Query Reformulation

- Use conversation history to disambiguate queries
- Expand pronouns and implicit references
- Maintain context across multi-turn interactions
Retrieval Optimization

Index Optimization

- Appropriate vector index algorithms (HNSW, IVF)
- Index parameter tuning for speed vs accuracy
- Regular index optimization and rebuilding
Filtering and Metadata

- Efficient metadata filtering for targeted search
- Date ranges, document types, authors, topics
- Combining filters with similarity search
Caching Strategies

- Cache frequent queries and their results
- Semantic caching for similar queries
- Precompute embeddings for common query patterns
5.5 Context Assembly and Response Generation

Context Construction

Information Selection Choosing the most relevant retrieved information:

- Top-k selection based on similarity scores
- Diversity sampling to avoid redundant information
- Relevance threshold filtering
- Context window management
Context Ordering Arranging retrieved information optimally:

- Most relevant information first
- Chronological ordering for time-sensitive content
- Logical flow for complex topics
- Source diversity for comprehensive coverage
Context Compression When retrieved information exceeds context limits:

- Summarization of individual chunks
- Intelligent truncation preserving key information
- Hierarchical information inclusion
- Multi-round retrieval and generation
Grounded Response Generation

Prompt Engineering for RAG

- Clear instructions to use only provided information
- Formatting requirements for citations
- Handling insufficient or contradictory information
- Balancing comprehensiveness with conciseness
Citation and Attribution

- Inline citations linking to source documents
- Source confidence scoring
- Multiple source verification
- Transparent handling of uncertainty
Quality Control

- Fact verification against sources
- Hallucination detection and prevention
- Consistency checking across multiple sources
- User feedback integration for improvement
5.6 RAG System Evaluation and Optimization

Evaluation Metrics

Retrieval Performance

- Recall@K: Percentage of relevant documents in top K results
- Precision@K: Percentage of top K results that are relevant
- MRR (Mean Reciprocal Rank): Average of reciprocal ranks of first relevant result
- NDCG (Normalized Discounted Cumulative Gain): Ranking quality metric
Generation Quality

- Faithfulness: How well the response reflects retrieved information
- Answer Relevance: How directly the response addresses the query
- Context Utilization: How effectively retrieved information is used
- Source Attribution Accuracy: Correctness of citations and references
End-to-End Performance

- Response Time: Total latency from query to response
- User Satisfaction: Human evaluation of response quality
- Task Completion Rate: Percentage of queries satisfactorily answered
- Cost Efficiency: Cost per query across different system configurations
Optimization Strategies

Iterative Improvement

- A/B testing different retrieval strategies
- Continuous evaluation and metric tracking
- User feedback integration and system adaptation
- Regular retraining of embedding models
System Tuning

- Chunk size and overlap optimization
- Retrieval threshold adjustment
- Context length and ordering optimization
- Model selection for different query types

Core Project: Building an AI-Powered Research Assistant

Project Overview - Knowledge-Powered Research System

In this chapter, we'll enhance your research assistant with comprehensive RAG capabilities, transforming it from a general-purpose AI tool into a specialized knowledge system that can work with your specific documents and information sources.

Enhanced System Capabilities:

1. Comprehensive Document Ingestion System

Multi-Format Document Processing Build a robust pipeline that can handle diverse document types:

Supported Formats:

- Text Documents: PDF, Word, plain text, markdown
- Web Content: HTML pages, articles, documentation sites
- Structured Data: CSV, JSON, Excel files, databases
- Code Repositories: GitHub repos, documentation, API references
- Academic Sources: Research papers, citations, bibliographies
Processing Features:

- Intelligent Text Extraction: OCR for scanned documents, table parsing
- Metadata Preservation: Author, date, source, document type
- Quality Assessment: Content quality scoring, duplicate detection
- Batch Processing: Efficient handling of large document collections
2. Advanced Semantic Search Infrastructure

Multi-Modal Vector Database Implement sophisticated search capabilities:

Search Technologies:

- Primary Vector Store: High-performance similarity search
- Hybrid Search Engine: Combining semantic and keyword search
- Metadata Indexing: Fast filtering by document attributes
- Real-Time Updates: Dynamic addition and removal of documents
Embedding Strategies:

- Multi-Model Support: Different embeddings for different content types
- Adaptive Chunking: Context-aware document segmentation
- Hierarchical Indexing: Document, section, and paragraph level search
- Query Optimization: Intelligent query expansion and reformulation
3. Intelligent Retrieval and Ranking

Advanced Retrieval Pipeline Create sophisticated information retrieval:

Retrieval Stages:

- Initial Candidate Selection: Fast approximate search across full corpus
- Semantic Reranking: Deep semantic analysis of top candidates
- Diversity Optimization: Ensuring varied perspectives in results
- Context Assembly: Optimal arrangement of retrieved information
Ranking Algorithms:

- Multi-Factor Scoring: Similarity, recency, authority, relevance
- User Personalization: Learning from interaction patterns
- Domain Adaptation: Specialized ranking for different research areas
- Confidence Estimation: Reliability scoring for retrieved information
4. Context-Aware Response Generation

Grounded Generation System Build responses that are verifiably accurate:

Generation Features:

- Source-Grounded Responses: All claims linked to specific sources
- Multi-Source Synthesis: Combining information from multiple documents
- Uncertainty Handling: Clear communication when information is insufficient
- Citation Management: Proper attribution and reference formatting
Quality Assurance:

- Fact Verification: Cross-checking claims against sources
- Hallucination Detection: Identifying unsupported statements
- Consistency Checking: Ensuring coherent information synthesis
- User Feedback Integration: Learning from user corrections and preferences
5. Knowledge Base Management

Dynamic Knowledge System Create maintainable, updatable knowledge infrastructure:

Management Features:

- Version Control: Tracking document updates and changes
- Access Control: User permissions and document security
- Analytics Dashboard: Usage patterns, popular documents, search trends
- Maintenance Tools: Duplicate detection, quality assessment, cleanup
Update Mechanisms:

- Incremental Updates: Adding new documents without full reindexing
- Content Monitoring: Automatic detection of outdated information
- Source Integration: APIs for real-time data feeds
- Collaborative Curation: Tools for subject matter experts to improve content
System Architecture Design

RAG-Enhanced Architecture:

┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐

│ User Query │────│ Query Analysis │────│ Retrieval Engine│

└─────────────────┘ └─────────────────┘ └─────────┬───────┘

│

┌─────────────────┐ ┌─────────────────┐ │

│ Document Store │────│ Vector Database │──────────────┘

└─────────────────┘ └─────────────────┘

│ │

│ ┌─────────────────┐

│ │ Embedding Model │

│ └─────────────────┘

│

┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐

│Document Ingestion│───│ Text Processing│───│ Chunk & Index │

└─────────────────┘ └─────────────────┘ └─────────────────┘

┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐

│Retrieved Context│────│Response Generator│────│ Final Response │

└─────────────────┘ └─────────────────┘ └─────────────────┘

Implementation Components

Core Modules Structure:

research_assistant/

├── ingestion/

│ ├── document_processor.py

│ ├── extractors/

│ │ ├── pdf_extractor.py

│ │ ├── web_extractor.py

│ │ └── office_extractor.py

│ └── quality_assessor.py

├── retrieval/

│ ├── vector_store.py

│ ├── embedding_manager.py

│ ├── hybrid_search.py

│ └── reranker.py

├── generation/

│ ├── context_assembler.py

│ ├── rag_generator.py

│ └── citation_manager.py

├── knowledge/

│ ├── knowledge_base.py

│ ├── update_manager.py

│ └── analytics.py

└── evaluation/

├── retrieval_evaluator.py

├── generation_evaluator.py

└── end_to_end_evaluator.py

Key Learning Objectives

Technical Mastery:

- Vector Database Operations: Efficient indexing, searching, and updating
- Embedding Strategies: Choosing and optimizing embeddings for different content
- Retrieval Engineering: Building high-performance search systems
- Context Management: Optimal information assembly and presentation
System Design Skills:

- Pipeline Architecture: End-to-end document processing workflows
- Performance Optimization: Balancing accuracy, speed, and cost
- Scalability Planning: Designing for growth in documents and users
- Quality Assurance: Systematic evaluation and improvement processes
Real-World Applications:

- Enterprise Knowledge Systems: Internal document search and Q&A
- Customer Support: Automated support with company-specific information
- Research Tools: Academic and professional research assistance
- Content Management: Intelligent content discovery and recommendation
Integration with Existing System

The RAG capabilities will seamlessly integrate with previous chapters:

Chapter 1-2 Foundation: Leveraging model selection and basic architecture Chapter 3 Prompt Engineering: Using optimized prompts for RAG scenarios Chapter 4 API Integration: Maintaining production-ready reliability and monitoring

This creates a comprehensive system that demonstrates enterprise-level AI capabilities while remaining educational and accessible for learning.

Conclusion

Retrieval-Augmented Generation represents a fundamental advancement in AI system capabilities, bridging the gap between static, training-data-limited models and dynamic, knowledge-grounded systems. Through this chapter, you've learned to build AI systems that can work with real-world information needs—accessing current data, private documents, and specialized knowledge domains.

Key Technical Achievements:

- Knowledge Infrastructure: Built sophisticated document ingestion and indexing systems
- Semantic Search Mastery: Implemented high-performance vector search with hybrid approaches
- Context Engineering: Developed skills in assembling and presenting retrieved information optimally
- Quality Assurance: Created evaluation frameworks for both retrieval and generation quality
- Production Integration: Designed scalable, maintainable knowledge systems
Professional Competencies Developed:

- Information Architecture: Understanding how to structure and organize knowledge for AI systems
- Search Engineering: Building search systems that balance performance, accuracy, and user experience
- Data Pipeline Design: Creating robust workflows for processing diverse content types
- Evaluation Methodology: Systematic approaches to measuring and improving system performance
- Product Thinking: Designing AI systems that solve real user problems with verifiable accuracy
Industry Applications Mastered: Your enhanced research assistant now demonstrates capabilities found in:

- Enterprise Knowledge Platforms: Internal document search and Q&A systems
- Customer Support Automation: Context-aware support with company-specific information
- Research and Analysis Tools: Professional research assistance with source attribution
- Content Discovery Systems: Intelligent information retrieval and recommendation
The RAG-powered system you've designed showcases advanced AI engineering skills that are immediately applicable to real-world projects. You've learned to handle the complexities of working with diverse information sources while maintaining accuracy, performance, and user trust through proper source attribution.

These skills position you to work on cutting-edge AI applications where the combination of reasoning capabilities and factual accuracy is essential—from legal AI assistants that must cite cases accurately to medical AI systems that require evidence-based responses.

End-of-Chapter Interactive Content

Assignment: Chapter 5 Core Project Submission

Objective: Design and implement a comprehensive RAG system that demonstrates mastery of knowledge-grounded AI applications with professional-grade capabilities.

Requirements:

- System Architecture and Design Document (1500-1800 words):
- Complete RAG system architecture with detailed component descriptions
- Document ingestion pipeline design for multiple content types
- Vector database selection and configuration justification
- Retrieval strategy including hybrid search and reranking approaches
- Context assembly and response generation methodology
- Evaluation framework for system performance and quality
- Scalability and maintenance considerations
- Knowledge Base Implementation:
- Support for at least 4 different document formats (PDF, web pages, structured data, code)
- Intelligent chunking strategy with overlap and hierarchy preservation
- Metadata extraction and indexing for enhanced filtering
- Quality assessment and duplicate detection mechanisms
- Version control and update management system
- Advanced Retrieval System:
- Vector database implementation with efficient similarity search
- Hybrid search combining semantic and keyword approaches
- Multi-stage retrieval with candidate selection and reranking
- Query enhancement and expansion techniques
- Configurable retrieval parameters for different use cases
- Grounded Generation Framework:
- Context assembly algorithm optimizing for relevance and diversity
- Source-attribution system with proper citation formatting
- Hallucination detection and mitigation strategies
- Multi-source information synthesis capabilities
- Uncertainty handling and confidence scoring
- Evaluation and Analytics System:
- Comprehensive metrics for retrieval performance (Recall@K, Precision@K, MRR)
- Generation quality assessment (faithfulness, relevance, attribution accuracy)
- End-to-end system performance monitoring
- A/B testing framework for system optimization
- User feedback integration and continuous improvement mechanisms
- Implementation Evidence:
- Complete code architecture with modular design
- Sample document processing and ingestion workflows
- Vector database integration with search examples
- RAG prompt templates and generation examples
- Performance benchmarking results and optimization evidence
- Comprehensive Evaluation Report (1000-1200 words):
- Quantitative analysis of retrieval performance across different document types
- Quality assessment of generated responses with source attribution accuracy
- Performance comparison between different chunking and retrieval strategies
- Cost-benefit analysis of vector database and embedding model choices
- User experience evaluation and improvement recommendations
- Lessons learned and best practices identified
Technical Specifications:

- System must process and index at least 1000 documents across multiple formats
- Achieve >85% retrieval recall for relevant information
- Generate responses with >90% source attribution accuracy
- Support sub-2-second query response times for most searches
- Implement proper error handling for malformed documents and failed retrievals
Advanced Challenges (Optional - Extra Credit):

- Multi-Modal RAG: Extend system to handle images, charts, and tables within documents
- Real-Time Knowledge Updates: Implement streaming updates for dynamic information sources
- Personalized Retrieval: Build user-specific relevance models based on interaction history
- Cross-Lingual RAG: Support queries and documents in multiple languages
- Federated Search: Integrate multiple external knowledge sources (APIs, databases, web)
Reflection Questions (Answer in 5-6 sentences each):

- How does implementing RAG change your understanding of AI system capabilities and limitations compared to standalone LLMs?
- What are the most critical trade-offs between retrieval quality, response speed, and system cost in production RAG systems?
- How would you adapt your RAG system design for different domains (legal, medical, technical documentation) while maintaining quality?
- What ethical considerations are most important when building AI systems that claim to provide factual, source-backed information?
Real-World Application Case Study (750-1000 words): Choose a specific industry or use case (healthcare, legal, customer support, research, etc.) and design a specialized RAG system for that domain. Include:

- Domain-specific challenges and requirements
- Specialized document types and processing needs
- Customized retrieval and ranking strategies
- Quality assurance and compliance considerations
- Success metrics and evaluation criteria
- Implementation timeline and resource requirements
Business Impact Analysis (500-750 words): Analyze the business value of your RAG system implementation:

- Quantified productivity improvements over traditional search methods
- Cost analysis comparing RAG vs. human expert consultation
- Risk mitigation through improved information accuracy and source tracking
- Competitive advantages gained through superior knowledge access
- ROI projections and success metrics for business stakeholders
Submission Format:

- Zip file containing: architecture documents (PDF), implementation code (Python), evaluation reports (PDF), case study analysis (PDF), business analysis (PDF), reflection answers (PDF)
- Include sample documents and knowledge base for demonstration
- ```
File naming: Chapter5_[YourLastName]_[YourFirstName].zip
```
Grading Criteria:

- Architecture and Design (25%): Comprehensive, scalable system design with clear component integration
- Technical Implementation (25%): Robust document processing, retrieval, and generation capabilities
- Evaluation and Quality (20%): Thorough performance analysis and quality assurance measures
- Innovation and Optimization (15%): Creative solutions and performance optimization strategies
- Real-World Application (15%): Practical understanding of business needs and implementation challenges
Due Date: [To be specified by instructor]

Interactive Quiz

[Link to online quiz covering RAG architecture, vector databases, retrieval strategies, and evaluation methodologies]

Hands-On Workshop Activities

Activity 1: Document Processing Challenge

- Students receive a diverse collection of documents (PDFs, web pages, spreadsheets, code repos)
- Competition to build the most effective ingestion pipeline
- Evaluation based on processing speed, quality, and metadata extraction accuracy
Activity 2: Retrieval Optimization Workshop

- Given a fixed document collection, teams optimize retrieval performance
- Test different chunking strategies, embedding models, and search approaches
- Present optimization results with before/after performance metrics
Activity 3: RAG vs. Human Expert Evaluation

- Students compare their RAG system responses with expert-generated answers
- Blind evaluation by peers rating accuracy, completeness, and usefulness
- Discussion of when RAG systems excel vs. when human expertise is essential
Discussion Forum Prompts

- Technical Challenges: "What was the most surprising technical challenge you encountered while building your RAG system, and how did you solve it?"
- Quality vs. Performance: "How do you balance the trade-off between retrieval quality and system performance? What compromises are acceptable in different use cases?"
- Future of Knowledge Systems: "How do you think RAG systems will evolve as LLMs become more capable? Will external knowledge retrieval become more or less important?"
Case Study Analysis Workshop

Scenario: "You're building a RAG system for a major law firm that needs to search through 50,000 legal documents, case files, and precedents. The system must provide responses that lawyers can trust in court."

Students must address:

- Technical Requirements: Precision demands, citation accuracy, update frequency
- Legal Compliance: Confidentiality, audit trails, regulatory compliance
- User Experience: Lawyer workflow integration, result verification, collaboration features
- Business Considerations: Cost justification, competitive advantage, risk management
Peer Review Activity

RAG System Peer Evaluation:

- Students exchange their implemented systems and test with their own document collections
- Provide detailed feedback on retrieval quality, response accuracy, and user experience
- Collaborate on identifying improvement opportunities and best practices
- Create shared knowledge base of effective RAG implementation strategies


## Tables (Imported)

### Table 1

| Term | Definition | Example/Context |
| --- | --- | --- |
| Retrieval-Augmented Generation (RAG) | AI approach combining information retrieval with text generation | ChatGPT with web browsing, customer support bots with knowledge bases |
| Vector Database | Database optimized for storing and searching high-dimensional embeddings | Pinecone, Weaviate, Chroma, FAISS |
| Embeddings | Dense vector representations that capture semantic meaning of text | Converting "artificial intelligence" to [0.2, -0.1, 0.8, ...] |
| Semantic Search | Finding information based on meaning rather than exact keyword matches | Searching "car problems" finds results about "automotive issues" |
| Document Chunking | Breaking large documents into smaller, manageable pieces for processing | Splitting a 50-page report into 500-word chunks |
| Vector Similarity | Measuring how semantically similar two pieces of text are | Cosine similarity between embedding vectors |
| Retrieval Pipeline | System for finding relevant information given a query | Query → embedding → similarity search → ranking → results |
| Context Window | Amount of text that can be included in a single LLM request | 4K, 16K, 128K tokens depending on model |
| Hybrid Search | Combining semantic search with traditional keyword/BM25 search | Using both vector similarity and exact term matching |
| Reranking | Improving initial search results through additional scoring methods | Using cross-encoder models to refine vector search results |
| Dense Retrieval | Using learned embeddings for information retrieval | BERT, Sentence Transformers for semantic search |
| Sparse Retrieval | Traditional keyword-based search methods | TF-IDF, BM25, Elasticsearch |
| Embedding Model | Neural network that converts text to vector representations | OpenAI text-embedding-ada-002, Sentence-BERT |
| Index | Data structure optimized for fast similarity search | HNSW, IVF, LSH for approximate nearest neighbor search |
| Metadata Filtering | Restricting search to documents with specific attributes | Only search documents from 2023, or from specific authors |
| Source Attribution | Linking generated responses back to original source documents | "According to the Q3 financial report..." with clickable citation |
| Knowledge Base | Organized collection of information for AI system access | Company documents, product manuals, research papers |
| Document Ingestion | Process of converting raw documents into searchable format | PDF → text extraction → chunking → embedding → indexing |
| Retrieval Recall | Percentage of relevant documents successfully found by search | Finding 8 out of 10 relevant documents = 80% recall |
| Retrieval Precision | Percentage of retrieved documents that are actually relevant | 7 relevant out of 10 retrieved documents = 70% precision |
| Hallucination Mitigation | Reducing AI's tendency to generate false or unsupported information | Grounding responses in retrieved facts, requiring citations |


---
## Chapter Wrap-Up

### Key Takeaways
- *(Add 4–6 key takeaways.)*

### Practice
- *(Add exercises, checks, or prompts.)*

### Project Milestone
- *(Define the milestone deliverable for this chapter.)*
