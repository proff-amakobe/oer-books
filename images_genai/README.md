# Chapter 2 Figures - Complete Set

## Overview

This directory contains all 11 professional-quality SVG figures for Chapter 2: "The Architecture of Understanding" of the textbook "Introduction to Generative AI with Large Language Models."

All figures are:
- ✅ Created as scalable SVG files (perfect for print and digital)
- ✅ Professionally designed with consistent color schemes
- ✅ Optimized for educational clarity
- ✅ Referenced correctly in the chapter text

---

## Figure Catalog

### Figure 2.1: Attention Mechanism Visualization
**File:** `figure_2_1_attention_mechanism.svg`

**Purpose:** Demonstrates how the attention mechanism weighs word relationships

**Key Features:**
- Shows the example sentence "The trophy doesn't fit in the suitcase because it is too big"
- Visualizes attention weights between "it" and potential referents
- Color-coded connections showing high/low attention scores
- Educational callout explaining the mechanism's conclusion

**Referenced in Section:** 2.1 (The Transformer Revolution)

---

### Figure 2.2: Multi-Head Attention
**File:** `figure_2_2_multi_head_attention.svg`

**Purpose:** Illustrates how different attention heads focus on different linguistic relationships

**Key Features:**
- Four distinct attention heads shown (Syntax, Semantics, References, Position)
- Example sentence demonstrating each head's specialty
- Shows how heads combine for complete understanding
- Color-coded by attention head type

**Referenced in Section:** 2.1 (The Transformer Revolution)

---

### Figure 2.3: Transformer Layer Stack
**File:** `figure_2_3_layer_stack.svg`

**Purpose:** Shows progressive sophistication through transformer depth

**Key Features:**
- Layers 1-10: Basic Understanding
- Layers 11-40: Complex Structures
- Layers 41-70: Abstract Reasoning
- Layers 71-96: Sophisticated Synthesis
- Visual flow from input to output with increasing complexity

**Referenced in Section:** 2.1 (The Transformer Revolution)

---

### Figure 2.4: Pre-training Process
**File:** `figure_2_4_pretraining.svg`

**Purpose:** Visualizes the massive-scale pre-training process

**Key Features:**
- Five data source categories (Books, Web, Papers, Code, News)
- Central training objective: "Predict the next token"
- List of emergent capabilities that arise from training
- Scale indicators (duration, cost, compute requirements)

**Referenced in Section:** 2.2 (From Random Weights to Intelligence)

---

### Figure 2.5: RLHF Process
**File:** `figure_2_5_rlhf.svg`

**Purpose:** Demonstrates Reinforcement Learning from Human Feedback

**Key Features:**
- Step-by-step RLHF process flow
- Comparison of good vs. poor responses
- Human evaluation stage
- Learning feedback loop
- Real example scenario

**Referenced in Section:** 2.2 (From Random Weights to Intelligence)

---

### Figure 2.6: Autoregressive Generation
**File:** `figure_2_6_autoregressive.svg`

**Purpose:** Shows token-by-token response generation

**Key Features:**
- Step-by-step generation process
- Example: "What is machine learning?"
- Shows progressive context building
- Illustrates how each token informs the next
- Final complete response

**Referenced in Section:** 2.2 (From Random Weights to Intelligence)

---

### Figure 2.7: Model Size Performance Comparison
**File:** `figure_2_7_model_comparison.svg`

**Purpose:** Comprehensive comparison table of small, medium, and large models

**Key Features:**
- Comparison across 5 dimensions:
  - Response Time
  - Cost per 1K tokens
  - Reasoning Ability
  - Best Use Cases
  - Example Models
- Color-coded for quick visual reference
- Key insight box with selection principle

**Referenced in Section:** 2.3 (The Size Question)

---

### Figure 2.8: Model Size vs. Task Complexity Decision Matrix
**File:** `figure_2_8_decision_matrix.svg`

**Purpose:** 2D matrix helping users select appropriate model size for task complexity

**Key Features:**
- X-axis: Model Size (Small, Medium, Large)
- Y-axis: Task Complexity (Low to Very High)
- Three zones:
  - ✓ Ideal Match (green) - optimal selections
  - Acceptable (yellow) - workable but suboptimal
  - ⚠️ Problematic (red) - wasteful or inadequate
- Example queries for each zone
- Quick reference key

**Referenced in Section:** 2.3 (The Size Question)

---

### Figure 2.9: Model Family Comparison Matrix
**File:** `figure_2_9_model_families.svg`

**Purpose:** Comprehensive overview of major LLM families and their specializations

**Key Features:**
- Four major families:
  - OpenAI GPT Family (Versatile Pioneers)
  - Anthropic Claude Family (Thoughtful Analysts)
  - Meta Llama Family (Open-Source Specialists)
  - Google PaLM/Gemini Family (Multilingual Innovators)
- Individual model variants within each family
- Strength indicators for each family
- Quick selection guide at bottom with common use cases

**Referenced in Section:** 2.4 (Meeting the Model Families)

---

### Figure 2.10: Enhanced Research Assistant Architecture
**File:** `figure_2_10_architecture.svg`

**Purpose:** System architecture diagram for the hands-on project

**Key Features:**
- Four distinct layers:
  1. User Interface (Streamlit)
  2. Intelligence Layer (Query Analyzer + Model Router)
  3. Optimization Layer (Cache, Cost Tracker, Performance Monitor)
  4. Generation Layer (Multiple API providers)
- Data flow arrows showing request/response path
- Component descriptions for each module
- Shows integration of all chapter concepts

**Referenced in Section:** 2.5 (Hands-On Project)

---

### Figure 2.11: Enhanced Interface with Performance Dashboard
**File:** `figure_2_11_interface_mockup.svg`

**Purpose:** Mockup of the actual Streamlit application interface

**Key Features:**
- Browser chrome for realism
- Left sidebar with performance metrics:
  - Today's Spend
  - Cache Hit Rate
  - Queries Today
  - Cost Saved
  - Model Usage pie chart
- Main area with:
  - Query input
  - Response display
  - Metadata (model, cost, time)
  - Selection reasoning
  - Fallback options
- Shows what students will actually build

**Referenced in Section:** 2.5 (Hands-On Project)

---

## Usage Guidelines

### In the Textbook

1. **Reference Format:** Use figure numbers consistently
   - Example: "As Figure 2.3 illustrates, transformer layers build progressively more sophisticated understanding..."

2. **Integration:** Figures should flow naturally within the text, not interrupt it
   - Place figures near their first reference
   - Ensure text discusses what the figure shows

3. **Captions:** Each figure has a descriptive title built into the SVG

### In Digital Formats

- SVG files scale perfectly for any screen size
- Can be embedded directly in HTML/Markdown
- Maintain quality when zoomed

### In Print

- SVGs can be converted to high-resolution PNGs or PDFs
- Recommended: 300 DPI for print
- All text remains legible even in black & white printing

---

## Color Scheme

Consistent colors used across all figures:

- **Blue (#3498db):** Primary concepts, OpenAI GPT, technical systems
- **Purple (#9b59b6):** Anthropic Claude, intermediate processes
- **Green (#27ae60):** Success states, Meta Llama, optimal choices
- **Orange (#f39c12):** Warnings, Google Gemini, cost tracking
- **Red (#e74c3c):** Problems, high costs, issues to avoid
- **Gray (#ecf0f1):** Neutral elements, backgrounds

---

## Technical Specifications

- **Format:** SVG (Scalable Vector Graphics)
- **Viewbox:** Varies by figure (optimized for content)
- **Text:** Arial/sans-serif fonts (web-safe)
- **File Size:** 4-11 KB (small and efficient)
- **Compatibility:** All modern browsers, design tools, word processors

---

## Modification Guide

To modify any figure:

1. Open the SVG file in a text editor or vector graphics program (Inkscape, Adobe Illustrator, Figma)
2. SVG is XML-based, so simple text changes can be made directly
3. Maintain consistent color schemes and fonts
4. Re-export as SVG to preserve scalability

Example: Updating text in Figure 2.1
```svg
<!-- Find this line -->
<text x="400" y="85">Response B is clearly better</text>

<!-- Change to -->
<text x="400" y="85">Response B demonstrates better quality</text>
```

---

## Quality Checklist

All figures meet these standards:

- ✅ Professional appearance suitable for publication
- ✅ Clear, readable text at multiple sizes
- ✅ Consistent styling across all figures
- ✅ Educational value (teach concepts visually)
- ✅ Accurate representation of chapter content
- ✅ Accessible color contrast
- ✅ Properly labeled and referenced

---

## Future Enhancements

Potential improvements for later editions:

1. **Interactive versions:** Add hover states and animations for digital textbook
2. **Accessibility:** Add ARIA labels for screen readers
3. **Translations:** Create versions in multiple languages
4. **Simplified versions:** Create simplified diagrams for quick reference cards
5. **Video walkthroughs:** Animated explanations of complex figures

---

## Questions or Issues?

If you need:
- Modified versions of any figure
- Additional figures for supplementary material
- Different formats (PNG, PDF, EPS)
- Custom color schemes for specific use cases

Contact information or modification instructions would go here.

---

**Created:** December 2024  
**Chapter:** 2 - The Architecture of Understanding  
**Textbook:** Introduction to Generative AI with Large Language Models  
**Author:** Dr. Moody
